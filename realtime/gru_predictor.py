"""
ì‹¤ì‹œê°„ ë°ëª¨ - GRU ì˜ˆì¸¡ê¸°
ZeroMQë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ í›„ GRU ëª¨ë¸ë¡œ ì˜¤ì—¼ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import zmq
import time
import numpy as np
import tensorflow as tf
from collections import deque, defaultdict

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.context_fusion.attention_context_encoder import create_attention_encoder
from src.model.gru_model import FedPerGRUModel
from realtime.utils import print_prediction_result, ZONES
from realtime.cleaning_executor import CleaningExecutor

# ZeroMQ ì„¤ì •
ZMQ_ENDPOINT = "ipc:///tmp/locus_sensors.ipc"

# ëª¨ë¸ ê²½ë¡œ
GRU_MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'gru', 'gru_model.keras')

# ì»¨í…ìŠ¤íŠ¸ ë²„í¼ ì„¤ì •
CONTEXT_BUFFER_SIZE = 30  # 30 íƒ€ì„ìŠ¤í…

# ROS ApproximateTimeSynchronizer ë°©ì‹ì˜ ë™ê¸°í™” ì„¤ì •
QUEUE_SIZE = 10  # ê° ì„¼ì„œë³„ë¡œ ì €ì¥í•  ë©”ì‹œì§€ ìˆ˜
SLOP = 0.5  # í—ˆìš© ì˜¤ì°¨ (ì´ˆ) - ì„¼ì„œ ê°„ ìµœëŒ€ ì‹œê°„ ì°¨ì´


class GRUPredictor:
    """
    GRU Predictor
    ZeroMQë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬ AttentionContextEncoderë¥¼ ê±°ì¹œ í›„, GRU ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self, enable_cleaning: bool = True, backend_url: str = "http://localhost:4000"):
        """
        GRU ì˜ˆì¸¡ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            enable_cleaning: ì²­ì†Œ ì‹¤í–‰ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
            backend_url: LocusBackend API URL
        """
        print("="*60)
        print("GRU Predictor Initializing...")
        print("="*60)

        # ZeroMQ Subscriber ì„¤ì • (BIND - êµ¬ë…ìê°€ ë°”ì¸ë“œí•˜ê³ , ë°œí–‰ìê°€ ì—°ê²°)
        self.zmq_context = zmq.Context()
        self.zmq_socket = self.zmq_context.socket(zmq.SUB)
        self.zmq_socket.bind(ZMQ_ENDPOINT)
        self.zmq_socket.setsockopt_string(zmq.SUBSCRIBE, "")  # ëª¨ë“  ë©”ì‹œì§€ êµ¬ë…
        print(f"ZeroMQ bound to {ZMQ_ENDPOINT}")
        print("Subscribed to all sensor messages")

        # Cleaning Executor ì´ˆê¸°í™”
        self.enable_cleaning = enable_cleaning
        if self.enable_cleaning:
            print("\nInitializing Cleaning Executor...")
            self.cleaning_executor = CleaningExecutor(
                backend_url=backend_url,
                device_id="robot_001",
                enable_backend=True
            )
        else:
            self.cleaning_executor = None
            print("\nCleaning execution disabled (prediction only mode)")

        # ëª¨ë¸ ë¡œë“œ
        print("\nLoading models...")
        print("  1. AttentionContextEncoder...")
        self.attention_encoder = create_attention_encoder(
            visual_dim=14,
            audio_dim=17,
            pose_dim=51,
            spatial_dim=4,  # 4 zones: balcony, bedroom, kitchen, living_room
            time_dim=10,
            context_dim=160
        )
        print("     AttentionContextEncoder loaded!")

        print(f"  2. GRU Model from {GRU_MODEL_PATH}...")
        self.gru_model = FedPerGRUModel(num_zones=4, context_dim=160)  # 4 zones
        self.gru_model.load(GRU_MODEL_PATH)
        print("     GRU Model loaded!")

        # ROS ApproximateTimeSynchronizer ë°©ì‹: ì„¼ì„œë³„ í
        self.sensor_queues = {
            'visual': deque(maxlen=QUEUE_SIZE),
            'audio': deque(maxlen=QUEUE_SIZE),
            'pose': deque(maxlen=QUEUE_SIZE),
            'spatial': deque(maxlen=QUEUE_SIZE),
            'time': deque(maxlen=QUEUE_SIZE)
        }

        # ì»¨í…ìŠ¤íŠ¸ ë²„í¼ (30 íƒ€ì„ìŠ¤í…)
        self.context_buffer = deque(maxlen=CONTEXT_BUFFER_SIZE)

        # í†µê³„ ì •ë³´
        self.timestep_count = 0
        self.prediction_count = 0
        self.sync_dropped = 0  # ë™ê¸°í™” ì‹¤íŒ¨ë¡œ íê¸°ëœ ë°ì´í„° ìˆ˜

        print("\nGRU Predictor ready!\n")

    def receive_messages(self):
        """
        ZeroMQ ë©”ì‹œì§€ë¥¼ ROS ApproximateTimeSynchronizer ë°©ì‹ìœ¼ë¡œ ìˆ˜ì‹ í•©ë‹ˆë‹¤.
        """
        try:
            # ë…¼ë¸”ë¡œí‚¹ ë°©ì‹ìœ¼ë¡œ íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ë©”ì‹œì§€ ìˆ˜ì‹ 
            if self.zmq_socket.poll(timeout=100):  # 100ms íƒ€ì„ì•„ì›ƒ
                message = self.zmq_socket.recv_pyobj()

                # ë©”ì‹œì§€ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                sensor_type = message.get('type')
                timestamp = message.get('timestamp')
                data = message.get('data')

                if sensor_type is None or timestamp is None or data is None:
                    return

                # í•´ë‹¹ ì„¼ì„œì˜ íì— ë©”ì‹œì§€ ì¶”ê°€
                if sensor_type in self.sensor_queues:
                    self.sensor_queues[sensor_type].append({
                        'timestamp': timestamp,
                        'data': data
                    })

                # ë™ê¸°í™” ì‹œë„
                self.try_synchronize()

        except Exception as e:
            print(f"Error in receive_messages: {e}")

    def try_synchronize(self):
        """
        ROS ApproximateTimeSynchronizer ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë™ê¸°í™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
        ëª¨ë“  íì— ë©”ì‹œì§€ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë™ê¸°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
        """
        # ëª¨ë“  íì— ìµœì†Œ 1ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not all(len(q) > 0 for q in self.sensor_queues.values()):
            return

        # 1. í”¼ë²—(pivot) íƒìƒ‰: ëª¨ë“  íì˜ ì²« ë²ˆì§¸ ë©”ì‹œì§€ ì¤‘ ê°€ì¥ ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„
        pivot = max(q[0]['timestamp'] for q in self.sensor_queues.values())

        # 2. ê° íì—ì„œ í”¼ë²—ì— ê°€ì¥ ê°€ê¹Œìš´ ë©”ì‹œì§€ íƒìƒ‰
        candidates = {}
        for sensor_type, queue in self.sensor_queues.items():
            # íì—ì„œ í”¼ë²—ì— ê°€ì¥ ê°€ê¹Œìš´ ë©”ì‹œì§€ë¥¼ ì°¾ìŒ
            best_msg = min(queue, key=lambda msg: abs(msg['timestamp'] - pivot))
            candidates[sensor_type] = best_msg

        # 3. ëª¨ë“  í›„ë³´ ë©”ì‹œì§€ê°€ í—ˆìš© ì˜¤ì°¨(slop) ì´ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        timestamps = [msg['timestamp'] for msg in candidates.values()]
        time_span = max(timestamps) - min(timestamps)

        if time_span <= SLOP:
            # ë™ê¸°í™” ì„±ê³µ: ë§¤ì¹­ëœ ë©”ì‹œì§€ ì¶”ì¶œ
            sensor_data = {sensor_type: msg['data']
                          for sensor_type, msg in candidates.items()}

            # ì‚¬ìš©ëœ ë©”ì‹œì§€ë¥¼ íì—ì„œ ì œê±°
            for sensor_type, matched_msg in candidates.items():
                queue = self.sensor_queues[sensor_type]
                # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì œê±°
                self.sensor_queues[sensor_type] = deque(
                    (msg for msg in queue if msg['timestamp'] != matched_msg['timestamp']),
                    maxlen=QUEUE_SIZE
                )

            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            avg_timestamp = sum(timestamps) / len(timestamps)
            self.process_context(sensor_data, avg_timestamp)
        else:
            # ë™ê¸°í™” ì‹¤íŒ¨: ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ íì—ì„œ ì œê±°
            oldest_sensor = min(self.sensor_queues.items(),
                               key=lambda x: x[1][0]['timestamp'] if len(x[1]) > 0 else float('inf'))
            if len(oldest_sensor[1]) > 0:
                oldest_sensor[1].popleft()
                self.sync_dropped += 1

    def process_context(self, sensor_data, timestamp_bucket):
        """
        ë™ê¸°í™”ëœ ì„¼ì„œ ë°ì´í„°ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        AttentionContextEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ 160ì°¨ì› ë²¡í„°ë¥¼ ìƒì„± í›„ ë²„í¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            sensor_data: {'visual': data, 'audio': data, ...} í˜•ì‹ì˜ ì„¼ì„œ ë°ì´í„°
            timestamp_bucket: íƒ€ì„ìŠ¤íƒ¬í”„ ë²„í‚·
        """
        try:
            # TensorFlow í…ì„œë¡œ ë³€í™˜
            context_dict = {
                'visual': tf.constant([sensor_data['visual']], dtype=tf.float32),
                'audio': tf.constant([sensor_data['audio']], dtype=tf.float32),
                'pose': tf.constant([sensor_data['pose']], dtype=tf.float32),
                'spatial': tf.constant([sensor_data['spatial']], dtype=tf.float32),
                'time': tf.constant([sensor_data['time']], dtype=tf.float32)
            }

            # AttentionContextEncoderë¥¼ í†µí•´ 160ì°¨ì› ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ìƒì„±
            context_160 = self.attention_encoder(context_dict, training=False)[0].numpy()

            # ë²„í¼ì— ì¶”ê°€
            self.context_buffer.append(context_160)
            self.timestep_count += 1

            print(f"[{self.timestep_count:04d}] Synced timestep @ {timestamp_bucket:.2f}s â†’ Buffer: {len(self.context_buffer)}/{CONTEXT_BUFFER_SIZE}")

            # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
            if len(self.context_buffer) == CONTEXT_BUFFER_SIZE:
                self.predict()

        except Exception as e:
            print(f"Error in process_context: {e}")
            import traceback
            traceback.print_exc()

    def predict(self):
        """
        GRU ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³ , ì²­ì†Œ ê²°ì •ì„ ë‚´ë¦½ë‹ˆë‹¤.
        """
        try:
            print("\n" + "="*60)
            print(f"Running GRU Prediction #{self.prediction_count + 1}...")
            print("="*60)

            # ë²„í¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            X = np.array(self.context_buffer).reshape(1, CONTEXT_BUFFER_SIZE, 160)

            # GRU ëª¨ë¸ë¡œ ì˜ˆì¸¡
            prediction = self.gru_model.predict(X)[0]

            # ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
            print_prediction_result(prediction, ZONES)

            self.prediction_count += 1

            # âœ¨ ì²­ì†Œ ì‹¤í–‰ (í™œì„±í™”ëœ ê²½ìš°)
            if self.enable_cleaning and self.cleaning_executor:
                print("\nğŸ¤– Triggering Cleaning Executor...")
                self.cleaning_executor.handle_prediction_sync(prediction)

            # ë²„í¼ ì´ˆê¸°í™”
            self.context_buffer.clear()
            print(f"\nBuffer cleared. Collecting next {CONTEXT_BUFFER_SIZE} timesteps...")
            print("="*60 + "\n")

        except Exception as e:
            print(f"Error in predict: {e}")
            import traceback
            traceback.print_exc()

    def run(self):
        """
        ì˜ˆì¸¡ê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (ZeroMQ í´ë§ ë£¨í”„).
        """
        print("GRU Predictor started!")
        print(f"  - Waiting for {CONTEXT_BUFFER_SIZE} timesteps of sensor data...")
        print("  - Press Ctrl+C to quit\n")

        try:
            while True:
                self.receive_messages()

        except KeyboardInterrupt:
            print("\nKeyboard interrupt, stopping...")

        finally:
            self.cleanup()

    def cleanup(self):
        """ì‚¬ìš©í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        print("\nCleaning up GRU Predictor...")
        self.zmq_socket.close()
        self.zmq_context.term()
        print("GRU Predictor stopped!")
        print(f"\nStatistics:")
        print(f"  - Total timesteps collected: {self.timestep_count}")
        print(f"  - Total predictions made: {self.prediction_count}")
        print(f"  - Sync failures (dropped): {self.sync_dropped}")


if __name__ == "__main__":
    predictor = GRUPredictor()
    predictor.run()
