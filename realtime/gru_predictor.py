"""
Realtime Demo - GRU Predictor
ZeroMQë¡œ ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ í›„ GRUë¡œ ì˜¤ì—¼ ì˜ˆì¸¡
"""

import sys
import os

# Add project root to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import zmq
import time
import numpy as np
import tensorflow as tf
from collections import deque

# Import existing models
from src.context_fusion.attention_context_encoder import create_attention_encoder
from src.model.gru_model import FedPerGRUModel
from realtime.utils import print_prediction_result, ZONES

# ZeroMQ ì„¤ì •
ZMQ_ENDPOINT = "ipc:///tmp/locus_sensors.ipc"

# ëª¨ë¸ ê²½ë¡œ
GRU_MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'gru', 'gru_model.keras')

# Context buffer ì„¤ì •
CONTEXT_BUFFER_SIZE = 30  # 30 timesteps


class GRUPredictor:
    """
    GRU Predictor
    ZeroMQë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ AttentionContextEncoder â†’ GRUë¡œ ì˜ˆì¸¡
    """

    def __init__(self):
        """Initialize GRU Predictor"""
        print("="*60)
        print("ğŸ§  GRU Predictor Initializing...")
        print("="*60)

        # ZeroMQ Subscriber ì„¤ì • (BIND - subscriber binds, publishers connect)
        self.zmq_context = zmq.Context()
        self.zmq_socket = self.zmq_context.socket(zmq.SUB)
        self.zmq_socket.bind(ZMQ_ENDPOINT)
        self.zmq_socket.setsockopt_string(zmq.SUBSCRIBE, "")  # Subscribe to all messages
        print(f"âœ“ ZeroMQ bound to {ZMQ_ENDPOINT}")
        print("âœ“ Subscribed to all sensor messages")

        # ëª¨ë¸ ë¡œë“œ
        print("\nğŸ“¦ Loading models...")
        print("  1. AttentionContextEncoder...")
        self.attention_encoder = create_attention_encoder(
            visual_dim=14,
            audio_dim=17,
            pose_dim=51,
            spatial_dim=7,
            time_dim=10,
            context_dim=160
        )
        print("     âœ“ AttentionContextEncoder loaded!")

        print(f"  2. GRU Model from {GRU_MODEL_PATH}...")
        self.gru_model = FedPerGRUModel(num_zones=7, context_dim=160)
        self.gru_model.load(GRU_MODEL_PATH)
        print("     âœ“ GRU Model loaded!")

        # ì„¼ì„œ ë°ì´í„° ë²„í¼
        self.current_context = {
            'visual': None,
            'audio': None,
            'pose': None,
            'spatial': None,
            'time': None
        }

        # Context buffer (30 timesteps)
        self.context_buffer = deque(maxlen=CONTEXT_BUFFER_SIZE)

        # í†µê³„
        self.timestep_count = 0
        self.prediction_count = 0

        print("\nâœ… GRU Predictor ready!\n")

    def receive_messages(self):
        """
        ZeroMQ ë©”ì‹œì§€ ìˆ˜ì‹  (í´ë§ ë°©ì‹)
        """
        try:
            # Non-blocking receive with timeout
            if self.zmq_socket.poll(timeout=100):  # 100ms timeout
                message = self.zmq_socket.recv_pyobj()

                # ë©”ì‹œì§€ íƒ€ì… í™•ì¸
                sensor_type = message.get('type')

                # ì„¼ì„œ ë°ì´í„° ì €ì¥
                if sensor_type in self.current_context:
                    self.current_context[sensor_type] = message.get('data')

                    # ë¡œê·¸ (ê°„ë‹¨í•˜ê²Œ)
                    # print(f"  [ZMQ] Received: {sensor_type}")

                # ëª¨ë“  ì„¼ì„œ ë°ì´í„°ê°€ ëª¨ì˜€ëŠ”ì§€ í™•ì¸
                if all(v is not None for v in self.current_context.values()):
                    self.process_context()

        except Exception as e:
            print(f"âš  Error in receive_messages: {e}")

    def process_context(self):
        """
        ëª¨ë“  ì„¼ì„œ ë°ì´í„°ê°€ ëª¨ì˜€ì„ ë•Œ ì²˜ë¦¬
        AttentionContextEncoderë¡œ 160-dim ìƒì„± í›„ ë²„í¼ì— ì¶”ê°€
        """
        try:
            # TensorFlow í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            context_dict = {
                'visual': tf.constant([self.current_context['visual']], dtype=tf.float32),
                'audio': tf.constant([self.current_context['audio']], dtype=tf.float32),
                'pose': tf.constant([self.current_context['pose']], dtype=tf.float32),
                'spatial': tf.constant([self.current_context['spatial']], dtype=tf.float32),
                'time': tf.constant([self.current_context['time']], dtype=tf.float32)
            }

            # AttentionContextEncoderë¡œ 160-dim ìƒì„±
            context_160 = self.attention_encoder(context_dict, training=False)[0].numpy()

            # Bufferì— ì¶”ê°€
            self.context_buffer.append(context_160)
            self.timestep_count += 1

            print(f"[{self.timestep_count:04d}] âœ… Context created â†’ Buffer: {len(self.context_buffer)}/{CONTEXT_BUFFER_SIZE} timesteps")

            # 30ê°œ ëª¨ì´ë©´ ì˜ˆì¸¡
            if len(self.context_buffer) == CONTEXT_BUFFER_SIZE:
                self.predict()

            # ì„¼ì„œ ë°ì´í„° ì´ˆê¸°í™”
            self.current_context = {k: None for k in self.current_context}

        except Exception as e:
            print(f"âš  Error in process_context: {e}")
            import traceback
            traceback.print_exc()

    def predict(self):
        """
        GRUë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        """
        try:
            print("\n" + "="*60)
            print(f"ğŸ§  Running GRU Prediction #{self.prediction_count + 1}...")
            print("="*60)

            # Bufferë¥¼ numpy arrayë¡œ ë³€í™˜
            X = np.array(self.context_buffer).reshape(1, CONTEXT_BUFFER_SIZE, 160)

            # GRU ì˜ˆì¸¡
            prediction = self.gru_model.predict(X, verbose=0)[0]

            # ê²°ê³¼ ì¶œë ¥
            print_prediction_result(prediction, ZONES)

            self.prediction_count += 1

            # Buffer ì´ˆê¸°í™” (ë‹¤ì‹œ 30ê°œ ëª¨ìœ¼ê¸°)
            self.context_buffer.clear()
            print(f"\nâœ“ Buffer cleared. Collecting next {CONTEXT_BUFFER_SIZE} timesteps...")
            print("="*60 + "\n")

        except Exception as e:
            print(f"âš  Error in predict: {e}")
            import traceback
            traceback.print_exc()

    def run(self):
        """
        Predictor ì‹¤í–‰ (ZeroMQ polling loop)
        """
        print("ğŸš€ GRU Predictor started!")
        print(f"  - Waiting for {CONTEXT_BUFFER_SIZE} timesteps of sensor data...")
        print("  - Press Ctrl+C to quit\n")

        try:
            while True:
                self.receive_messages()

        except KeyboardInterrupt:
            print("\nâš  Keyboard interrupt, stopping...")

        finally:
            self.cleanup()

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\nğŸ§¹ Cleaning up GRU Predictor...")
        self.zmq_socket.close()
        self.zmq_context.term()
        print("âœ“ GRU Predictor stopped!")
        print(f"\nStatistics:")
        print(f"  - Total timesteps collected: {self.timestep_count}")
        print(f"  - Total predictions made: {self.prediction_count}")


if __name__ == "__main__":
    predictor = GRUPredictor()
    predictor.run()
