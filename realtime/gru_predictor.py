"""
Realtime Demo - GRU Predictor
MQTTë¡œ ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ í›„ GRUë¡œ ì˜¤ì—¼ ì˜ˆì¸¡
"""

import sys
import os

# Add project root to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import paho.mqtt.client as mqtt
import pickle
import time
import numpy as np
import tensorflow as tf
from collections import deque

# Import existing models
from src.context_fusion.attention_context_encoder import create_attention_encoder
from src.model.gru_model import FedPerGRUModel
from realtime.utils import print_prediction_result, ZONES

# MQTT ì„¤ì •
MQTT_BROKER = "localhost"
MQTT_PORT = 1883

# ëª¨ë¸ ê²½ë¡œ
GRU_MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'gru', 'gru_model.keras')

# Context buffer ì„¤ì •
CONTEXT_BUFFER_SIZE = 30  # 30 timesteps


class GRUPredictor:
    """
    GRU Predictor
    MQTTë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ AttentionContextEncoder â†’ GRUë¡œ ì˜ˆì¸¡
    """

    def __init__(self):
        """Initialize GRU Predictor"""
        print("="*60)
        print("ğŸ§  GRU Predictor Initializing...")
        print("="*60)

        # MQTT í´ë¼ì´ì–¸íŠ¸
        self.mqtt_client = mqtt.Client("gru_predictor")
        self.mqtt_client.on_message = self.on_message
        self.mqtt_client.connect(MQTT_BROKER, MQTT_PORT)
        print(f"âœ“ MQTT connected to {MQTT_BROKER}:{MQTT_PORT}")

        # ëª¨ë“  ì„¼ì„œ êµ¬ë…
        self.mqtt_client.subscribe("sensor/#")
        print("âœ“ Subscribed to sensor/#")

        # ëª¨ë¸ ë¡œë“œ
        print("\nğŸ“¦ Loading models...")
        print("  1. AttentionContextEncoder...")
        self.attention_encoder = create_attention_encoder(
            visual_dim=14,
            audio_dim=17,
            pose_dim=51,
            spatial_dim=7,
            time_dim=10,
            context_dim=160
        )
        print("     âœ“ AttentionContextEncoder loaded!")

        print(f"  2. GRU Model from {GRU_MODEL_PATH}...")
        self.gru_model = FedPerGRUModel(num_zones=7, context_dim=160)
        self.gru_model.load(GRU_MODEL_PATH)
        print("     âœ“ GRU Model loaded!")

        # ì„¼ì„œ ë°ì´í„° ë²„í¼
        self.current_context = {
            'visual': None,
            'audio': None,
            'pose': None,
            'spatial': None,
            'time': None
        }

        # Context buffer (30 timesteps)
        self.context_buffer = deque(maxlen=CONTEXT_BUFFER_SIZE)

        # í†µê³„
        self.timestep_count = 0
        self.prediction_count = 0

        print("\nâœ… GRU Predictor ready!\n")

    def on_message(self, client, userdata, msg):
        """
        MQTT ë©”ì‹œì§€ ìˆ˜ì‹  ì½œë°±

        Args:
            msg: MQTT message
        """
        try:
            # ë©”ì‹œì§€ íŒŒì‹±
            topic = msg.topic  # "sensor/visual"
            data = pickle.loads(msg.payload)

            sensor_type = topic.split('/')[-1]  # "visual"

            # ì„¼ì„œ ë°ì´í„° ì €ì¥
            if sensor_type in self.current_context:
                self.current_context[sensor_type] = data[sensor_type]

                # ë¡œê·¸ (ê°„ë‹¨í•˜ê²Œ)
                # print(f"  [MQTT] Received: {sensor_type}")

            # ëª¨ë“  ì„¼ì„œ ë°ì´í„°ê°€ ëª¨ì˜€ëŠ”ì§€ í™•ì¸
            if all(v is not None for v in self.current_context.values()):
                self.process_context()

        except Exception as e:
            print(f"âš  Error in on_message: {e}")

    def process_context(self):
        """
        ëª¨ë“  ì„¼ì„œ ë°ì´í„°ê°€ ëª¨ì˜€ì„ ë•Œ ì²˜ë¦¬
        AttentionContextEncoderë¡œ 160-dim ìƒì„± í›„ ë²„í¼ì— ì¶”ê°€
        """
        try:
            # TensorFlow í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            context_dict = {
                'visual': tf.constant([self.current_context['visual']], dtype=tf.float32),
                'audio': tf.constant([self.current_context['audio']], dtype=tf.float32),
                'pose': tf.constant([self.current_context['pose']], dtype=tf.float32),
                'spatial': tf.constant([self.current_context['spatial']], dtype=tf.float32),
                'time': tf.constant([self.current_context['time']], dtype=tf.float32)
            }

            # AttentionContextEncoderë¡œ 160-dim ìƒì„±
            context_160 = self.attention_encoder(context_dict, training=False)[0].numpy()

            # Bufferì— ì¶”ê°€
            self.context_buffer.append(context_160)
            self.timestep_count += 1

            print(f"[{self.timestep_count:04d}] âœ… Context created â†’ Buffer: {len(self.context_buffer)}/{CONTEXT_BUFFER_SIZE} timesteps")

            # 30ê°œ ëª¨ì´ë©´ ì˜ˆì¸¡
            if len(self.context_buffer) == CONTEXT_BUFFER_SIZE:
                self.predict()

            # ì„¼ì„œ ë°ì´í„° ì´ˆê¸°í™”
            self.current_context = {k: None for k in self.current_context}

        except Exception as e:
            print(f"âš  Error in process_context: {e}")
            import traceback
            traceback.print_exc()

    def predict(self):
        """
        GRUë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        """
        try:
            print("\n" + "="*60)
            print(f"ğŸ§  Running GRU Prediction #{self.prediction_count + 1}...")
            print("="*60)

            # Bufferë¥¼ numpy arrayë¡œ ë³€í™˜
            X = np.array(self.context_buffer).reshape(1, CONTEXT_BUFFER_SIZE, 160)

            # GRU ì˜ˆì¸¡
            prediction = self.gru_model.predict(X, verbose=0)[0]

            # ê²°ê³¼ ì¶œë ¥
            print_prediction_result(prediction, ZONES)

            self.prediction_count += 1

            # Buffer ì´ˆê¸°í™” (ë‹¤ì‹œ 30ê°œ ëª¨ìœ¼ê¸°)
            self.context_buffer.clear()
            print(f"\nâœ“ Buffer cleared. Collecting next {CONTEXT_BUFFER_SIZE} timesteps...")
            print("="*60 + "\n")

        except Exception as e:
            print(f"âš  Error in predict: {e}")
            import traceback
            traceback.print_exc()

    def run(self):
        """
        Predictor ì‹¤í–‰ (MQTT loop)
        """
        print("ğŸš€ GRU Predictor started!")
        print(f"  - Waiting for {CONTEXT_BUFFER_SIZE} timesteps of sensor data...")
        print("  - Press Ctrl+C to quit\n")

        try:
            self.mqtt_client.loop_forever()

        except KeyboardInterrupt:
            print("\nâš  Keyboard interrupt, stopping...")

        finally:
            self.cleanup()

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\nğŸ§¹ Cleaning up GRU Predictor...")
        self.mqtt_client.disconnect()
        print("âœ“ GRU Predictor stopped!")
        print(f"\nStatistics:")
        print(f"  - Total timesteps collected: {self.timestep_count}")
        print(f"  - Total predictions made: {self.prediction_count}")


if __name__ == "__main__":
    predictor = GRUPredictor()
    predictor.run()
