"""
Realtime Demo - Visual Sensor (YOLO)
ì›¹ìº ìœ¼ë¡œ ê°ì²´ ê°ì§€ í›„ ZeroMQë¡œ ì „ì†¡
"""

import sys
import os

# Add project root to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import cv2
from ultralytics import YOLO
import zmq
import time
import numpy as np
from realtime.utils import yolo_results_to_14dim, YOLO_CLASSES

# ZeroMQ ì„¤ì •
ZMQ_ENDPOINT = "ipc:///tmp/locus_sensors.ipc"

# YOLO ëª¨ë¸ ê²½ë¡œ
YOLO_MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'yolo', 'best.pt')


class VisualSensor:
    """
    YOLO ê¸°ë°˜ Visual Sensor
    ì›¹ìº ì—ì„œ í”„ë ˆìž„ì„ ì½ê³  YOLOë¡œ ê°ì²´ ê°ì§€ í›„ ZeroMQë¡œ ì „ì†¡
    """

    def __init__(self, camera_id=0):
        """
        Initialize Visual Sensor

        Args:
            camera_id: ì›¹ìº  ID (ê¸°ë³¸ê°’: 0)
        """
        print("="*60)
        print("ðŸŽ¥ Visual Sensor (YOLO) Initializing...")
        print("="*60)

        # ZeroMQ Publisher ì„¤ì •
        self.zmq_context = zmq.Context()
        self.zmq_socket = self.zmq_context.socket(zmq.PUB)
        self.zmq_socket.connect(ZMQ_ENDPOINT)
        print(f"âœ“ ZeroMQ connected to {ZMQ_ENDPOINT}")

        # YOLO ëª¨ë¸ ë¡œë“œ
        print(f"Loading YOLO model from: {YOLO_MODEL_PATH}")
        self.yolo_model = YOLO(YOLO_MODEL_PATH)
        print("âœ“ YOLO model loaded!")

        # ì›¹ìº  ì´ˆê¸°í™”
        self.cap = cv2.VideoCapture(camera_id)
        if not self.cap.isOpened():
            raise RuntimeError(f"Cannot open camera {camera_id}")
        print(f"âœ“ Camera {camera_id} opened!")

        print("\nâœ… Visual Sensor ready!\n")

    def run(self, interval=1.0, show_window=False):
        """
        ì„¼ì„œ ì‹¤í–‰ (ë©”ì¸ ë£¨í”„)

        Args:
            interval: ì „ì†¡ ì£¼ê¸° (ì´ˆ)
            show_window: ì›¹ìº  í™”ë©´ í‘œì‹œ ì—¬ë¶€
        """
        print("ðŸš€ Starting Visual Sensor loop...")
        print(f"  - Interval: {interval}s")
        print(f"  - Show window: {show_window}")
        print("  - Press 'q' to quit\n")

        frame_count = 0

        try:
            while True:
                # í”„ë ˆìž„ ì½ê¸°
                ret, frame = self.cap.read()
                if not ret:
                    print("âš  Failed to read frame, retrying...")
                    time.sleep(0.1)
                    continue

                # YOLO ì¶”ë¡ 
                results = self.yolo_model(frame, verbose=False)

                # 14-dim ë²¡í„° ìƒì„±
                visual_vec = yolo_results_to_14dim(results)

                # ê°ì§€ëœ ê°ì²´ í™•ì¸
                detected_indices = np.where(visual_vec > 0)[0]
                detected_objects = [YOLO_CLASSES[i] for i in detected_indices]

                # ZeroMQ ì „ì†¡
                message = {
                    'type': 'visual',
                    'data': visual_vec,
                    'timestamp': time.time(),
                    'frame_count': frame_count
                }
                self.zmq_socket.send_pyobj(message)

                # ë¡œê·¸ ì¶œë ¥
                frame_count += 1
                print(f"[{frame_count:04d}] ðŸ“¹ Visual â†’ ZMQ: {len(detected_objects)} objects detected", end="")
                if detected_objects:
                    print(f" ({', '.join(detected_objects[:3])}{'...' if len(detected_objects) > 3 else ''})")
                else:
                    print(" (none)")

                # í™”ë©´ í‘œì‹œ (ì˜µì…˜)
                if show_window:
                    annotated = results[0].plot()
                    cv2.imshow("YOLO Visual Sensor", annotated)

                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        print("\nâš  User pressed 'q', stopping...")
                        break

                # ëŒ€ê¸°
                time.sleep(interval)

        except KeyboardInterrupt:
            print("\nâš  Keyboard interrupt, stopping...")

        finally:
            self.cleanup()

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\nðŸ§¹ Cleaning up Visual Sensor...")
        self.cap.release()
        cv2.destroyAllWindows()
        self.zmq_socket.close()
        self.zmq_context.term()
        print("âœ“ Visual Sensor stopped!")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Visual Sensor (YOLO)")
    parser.add_argument("--interval", type=float, default=1.0,
                        help="Sensing interval in seconds (default: 1.0)")
    parser.add_argument("--camera", type=int, default=0,
                        help="Camera ID (default: 0)")
    parser.add_argument("--show", action="store_true",
                        help="Show webcam window")

    args = parser.parse_args()

    # ì„¼ì„œ ì‹œìž‘
    sensor = VisualSensor(camera_id=args.camera)
    sensor.run(interval=args.interval, show_window=args.show)
